{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c352600-de4f-4242-89aa-fafd2745338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb88fb-0aa4-4fa8-b0be-a63860c9d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_inicial = 'http://www.revistagastroenterologiamexico.org/es-numeros-anteriores-2008'\n",
    "url_root = 'http://www.revistagastroenterologiamexico.org/es-numeros-anteriores-2008'\n",
    "r=requests.get(url_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d85de8-a1de-4b58-a2af-bca93f9bb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc62e5-70a5-4e0f-9d2f-21dd6284fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = soup.find('div', class_='sumarios decada-2008')\n",
    "volumen=box.findAll('div',class_='sumario row')\n",
    "vol = [x.find('a').get('href')for x in volumen] \n",
    "vol = [urljoin (url_root, i) for i in vol]\n",
    "vol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f84020-a2ae-4182-bb17-59f08c39fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2 =[]\n",
    "for i in vol: \n",
    "    url_inicial1=i \n",
    "    r1 = requests.get(url_inicial1)\n",
    "    soup1 = BeautifulSoup(r1.text, 'html.parser')\n",
    "    box1 = soup1.find('div', class_='collFull') \n",
    "    volumen1=box1.findAll('div', class_='item')\n",
    "    vol1 = [x.find('a').get('href')for x in volumen1]\n",
    "    vol1 = [urljoin (url_root, i) for i in vol1]\n",
    "    vol2 = [urljoin (url_root, i) for i in vol2]\n",
    "    vol2+=vol1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59877b23-97dd-4ba1-8e5f-713fbb4bca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b15f98-c7a2-4786-91e5-9d7b9472d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_items(sopa,url):\n",
    "    box1 = soup1.find('div', class_='collFull') \n",
    "    volumen1=box1.findAll('div', class_='item')\n",
    "    vol1 = [x.find('a').get('href')for x in volumen1]\n",
    "    return vol2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0443c1-5c58-44fc-a5b7-e31889d58c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_items=[]\n",
    "i=0\n",
    "while i<1:\n",
    "    i+=1\n",
    "    print(f'Estoy en la pagina {url_inicial}')\n",
    "    r_pag=requests.get(url_inicial)\n",
    "    s_p=BeautifulSoup(r_pag.text,'html.parser')\n",
    "    links=get_url_items(s_p, url_inicial)\n",
    "    links_items.append(links) \n",
    "    next_a=s_p.select('li.next > a')\n",
    "    if not next_a or not next_a[0].get('href'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca523c-7d1f-4168-bc22-3892f01ee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scraper=[]\n",
    "for i in links_items:\n",
    "    for j in i:\n",
    "        list_scraper.append(j)\n",
    "len(list_scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b579c-a153-4856-b231-8e2cd434f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "uno=list_scraper[0]\n",
    "r_item=requests.get(uno)\n",
    "s_item=BeautifulSoup(r_item.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871527c-f809-40af-88c1-e71a10cad2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para iniciar el escraper de cada libro\n",
    "def scraper_book(url):\n",
    "    content_book={}\n",
    "    r=requests.get(url)\n",
    "    tire='Revista de Gastroenterología de México'\n",
    "    a='III. Medicina y Ciencias de la Salud'\n",
    "    tem='Gastroenterología'\n",
    "    s_item=BeautifulSoup(r.text,'html.parser')\n",
    "    #titulo de revista\n",
    "    try:\n",
    "        titulo=tire\n",
    "        content_book['Titulo Revista']=tire\n",
    "    except AttributeError:\n",
    "        content_book['Titulo Revista']=None\n",
    "    #area\n",
    "    try:\n",
    "        area=a\n",
    "        content_book['Area']=a\n",
    "    except AttributeError:\n",
    "        content_book['Area']=None\n",
    "    #tematica\n",
    "    try:\n",
    "        tema=tem\n",
    "        content_book['Tematica']=tem\n",
    "    except AttributeError:\n",
    "        content_book['Tematica']=None\n",
    "    #titulo articulo\n",
    "    try:\n",
    "        titu=s_item.find('div', class_='elsevierItemTitulo').get_text(strip=True)\n",
    "        content_book['Titulo Articulo']=titu\n",
    "    except AttributeError:\n",
    "        content_book['Titulo Articulo']=None\n",
    "    #resumen\n",
    "    try:\n",
    "        resu=s_item.find('div', class_='elsevierItemTextoCompletoTexto').get_text(strip=True)\n",
    "        content_book['Resumen']=resu\n",
    "    except AttributeError:\n",
    "        content_book['Resumen']=None\n",
    "    #abstract\n",
    "    try:\n",
    "        abst=s_item.find('div', class_='item cover_image').get_text(strip=True)\n",
    "        content_book['Abstract']=abst\n",
    "    except AttributeError:\n",
    "        content_book['Abstract']=None\n",
    "    #Link incial\n",
    "    try:\n",
    "        linkart=url\n",
    "        content_book['Link Articulo']=linkart\n",
    "    except AttributeError:\n",
    "        content_book['Link Articulo']=None\n",
    "        linkart = [urljoin (url_root, i) for i in linkart]\n",
    "    #link articulo\n",
    "    try:\n",
    "        link=s_item.find('div', class_='right').find('a').get('href')\n",
    "        content_book['Link PDF']=urljoin(url_root, link)\n",
    "    except AttributeError:\n",
    "        content_book['Link PDF']=None\n",
    "        link = [urljoin (url_root, i) for i in link]\n",
    "    return content_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478281d-6e77-4198-9b31-9c3cab5275a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scraper=list_scraper[0:101]\n",
    "datos_book=[]\n",
    "for idx, i in enumerate(list_scraper):\n",
    "    print(f'estas escrapeando la pag {idx}')\n",
    "    datos_book.append(scraper_book(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6a1c6-1235-4874-9640-a282e35201fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalogo=pd.DataFrame(datos_book)\n",
    "df_catalogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8beba5a-1872-46f1-b029-47b777d9a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_catalogo.to_csv('Revista19.16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a210c-f000-4953-95b5-6069f30debfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19c7de-531c-46f2-88b0-0a85005b5372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
